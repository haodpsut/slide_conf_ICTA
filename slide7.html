<!-- SLIDE: Model Architectures -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Methodology: Model Architectures</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Segoe+UI:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <div class="slide-canvas antialiased bg-white flex flex-col p-12 relative">
        <h1 class="text-4xl font-bold text-center" style="color: #003366;">Methodology: Model Architectures</h1>
        <div class="w-24 h-1.5 mt-3 mx-auto" style="background-color: #2196F3;"></div>
        
        <div class="flex-grow grid grid-cols-1 md:grid-cols-3 gap-8 items-stretch mt-10">
            <!-- Vanilla CNN -->
            <div class="bg-gray-50 rounded-lg p-6 text-center shadow">
                <i class="fas fa-network-wired text-5xl mb-4 text-gray-400"></i>
                <h2 class="text-2xl font-bold text-gray-800">Vanilla CNN</h2>
                <p class="text-lg text-gray-600 mt-2">Takes raw image as input.</p>
                <ul class="text-left mt-4 space-y-2 list-disc list-inside">
                    <li>Three convolutional layers (16, 32, 64 filters).</li>
                    <li>2x2 MaxPooling after each conv layer.</li>
                    <li>Final dense layer for output.</li>
                    <li>~0.5M parameters.</li>
                </ul>
            </div>
            
            <!-- Residual CNN -->
            <div class="bg-blue-50 rounded-lg p-6 text-center shadow-lg border-2 border-blue-500">
                <i class="fas fa-recycle text-5xl mb-4 text-blue-500"></i>
                <h2 class="text-2xl font-bold text-blue-800">Residual CNN (ResNet)</h2>
                <p class="text-lg text-gray-700 mt-2">Our proposed robust model.</p>
                <ul class="text-left mt-4 space-y-2 list-disc list-inside">
                    <li>A ResNet-10 architecture.</li>
                    <li>Uses <em class="italic">skip connections</em> to mitigate vanishing gradients.</li>
                    <li>Ideal for processing low-resolution or degraded images.</li>
                    <li>~0.7M parameters.</li>
                </ul>
            </div>
            
            <!-- XGBoost -->
            <div class="bg-gray-50 rounded-lg p-6 text-center shadow">
                <i class="fas fa-tree text-5xl mb-4 text-green-600"></i>
                <h2 class="text-2xl font-bold text-gray-800">XGBoost</h2>
                <p class="text-lg text-gray-600 mt-2">Processes the extracted feature vector.</p>
                 <ul class="text-left mt-4 space-y-2 list-disc list-inside">
                    <li>A powerful gradient boosting algorithm.</li>
                    <li>Effective for tabular data (our feature vector).</li>
                    <li>Hyperparameters tuned via Bayesian Optimization.</li>
                </ul>
            </div>
        </div>

        <div class="slide-footer">
            <div class="w-1/4 text-left">Robust Quishing Detection</div>
            <div class="w-1/2 text-center">Conference Presentation</div>
            <div id="slide-counter" class="w-1/4 text-right"></div>
        </div>
    </div>
    <a id="prev-slide" class="nav-button left-0"><i class="fas fa-chevron-left"></i></a>
    <a id="next-slide" class="nav-button right-0"><i class="fas fa-chevron-right"></i></a>
    <script src="navigation.js" defer></script>
</body>
</html>